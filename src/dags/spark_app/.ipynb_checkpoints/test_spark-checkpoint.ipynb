{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6456b6ac-a3db-4cd8-803f-0e6ad683ea49",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pyspark\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "# pyspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "# Minio\n",
    "from minio import Minio\n",
    "from io import BytesIO\n",
    "from minio.error import S3Error\n",
    "# Utility\n",
    "import json, sys, os, datetime\n",
    "from gecko_transform import *\n",
    "\n",
    "# Support function\n",
    "def connect_to_minio():\n",
    "    access_key = 'vp821YRUCKiTgGoMEjR6'\n",
    "    secret_key = 'TkrExNxV2ozU3l9O59nk561fCSONQZSWvrZKoOpK'\n",
    "    client = Minio(\n",
    "        endpoint='localhost:9000',  # Use the HTTP port\n",
    "        access_key=access_key,\n",
    "        secret_key=secret_key,\n",
    "        secure=False  # Ensure this is False for HTTP\n",
    "    )\n",
    "    return client\n",
    "\n",
    "client = connect_to_minio()\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark with Minio\") \\\n",
    "    .config(\"spark.log.level\", \"WARN\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.1\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"my_account\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"123456789\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://localhost:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set('spark.sql.caseSensitive', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b6de769-357d-4ca3-8cb2-b3893919afb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef161a75-c6f8-4814-aad0-6a4070466c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----------+------------------+---------+--------------------+---------------+\n",
      "|  page|            category|last_7_days|        market_cap|num_coins|                 url|volume_last_day|\n",
      "+------+--------------------+-----------+------------------+---------+--------------------+---------------+\n",
      "|page-1|        Layer 1 (L1)|       4.8%|$1,640,086,661,795|      167|https://www.coing...|$50,554,436,223|\n",
      "|page-1| Proof of Work (PoW)|       4.3%|$1,162,266,073,871|      279|https://www.coing...|$33,303,263,088|\n",
      "|page-1|Smart Contract Pl...|       5.6%|  $523,319,682,057|      252|https://www.coing...|$20,228,045,786|\n",
      "|page-1|Proof of Stake (PoS)|       6.0%|  $488,978,397,404|      191|https://www.coing...|$19,203,502,358|\n",
      "|page-1|Andreessen Horowi...|       4.9%|  $419,686,201,788|       52|https://www.coing...|$18,813,533,809|\n",
      "+------+--------------------+-----------+------------------+---------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define schema\n",
    "bars_schema = StructType([\n",
    "    StructField(\"timestamp\", StringType(), True),\n",
    "    StructField(\"open_time\", LongType(), True),\n",
    "    StructField(\"symbol_name\", StringType(), True),\n",
    "    StructField(\"open\", DoubleType(), True),\n",
    "    StructField(\"high\", DoubleType(), True),\n",
    "    StructField(\"low\", DoubleType(), True),\n",
    "    StructField(\"close\", DoubleType(), True),\n",
    "    StructField(\"vol\", DoubleType(), True),\n",
    "    StructField(\"close_time\", LongType(), True),\n",
    "    StructField(\"quote_asset_vol\", DoubleType(), True),\n",
    "    StructField(\"num_trades\", IntegerType(), True),\n",
    "    StructField(\"taker_base_vol\", DoubleType(), True),\n",
    "    StructField(\"taker_quote_vol\", DoubleType(), True),\n",
    "    StructField(\"ignore\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Read Files\n",
    "# Binance\n",
    "# bars_df = spark.read.csv(\"s3a://binance-bars/*.csv\", header=True, inferSchema=True)\n",
    "# latest_prices_df = spark.read.option(\"multiline\", \"true\").option(\"header\", \"true\").json(\"s3a://binance-latest-prices/*.json\")\n",
    "# symbols_df = spark.read.option(\"multiline\", \"true\").option(\"header\", \"true\").json(\"s3a://binance-symbols/*.json\")\n",
    "\n",
    "# Gecko\n",
    "category_df = spark.read.option(\"multiline\", \"true\").option(\"header\", \"true\").json(\"s3a://gecko-category/category.json\")\n",
    "category_details_df = spark.read.option(\"multiline\", \"true\").option(\"header\", \"true\").json(\"s3a://gecko-category-details/category-details.json\")\n",
    "\n",
    "# Transformation\n",
    "# symbols_df = symbols_df.withColumn(\"symbols\", explode(col(\"symbols\")))\n",
    "# symbols_df = symbols_df.select(\n",
    "#     col(\"serverTime\"),\n",
    "#     col(\"symbols.symbol\"),\n",
    "#     col(\"symbols.status\"),\n",
    "#     col(\"symbols.allowTrailingStop\"),\n",
    "#     col(\"symbols.baseAsset\"),\n",
    "#     col(\"symbols.baseAssetPrecision\"),\n",
    "#     col(\"symbols.baseCommissionPrecision\")\n",
    "# )\n",
    "category_df = flatten_category(category_df, spark)\n",
    "category_details_df = flatten_category_details(category_details_df, spark)\n",
    "\n",
    "category_df.show(5)\n",
    "\n",
    "# Create bucket if not exists\n",
    "spark_bucket = \"spark-output\"\n",
    "if not client.bucket_exists(spark_bucket):\n",
    "    client.make_bucket(spark_bucket)\n",
    "\n",
    "# # Write to Minio\n",
    "# bars_df.write \\\n",
    "#         .format(\"csv\") \\\n",
    "#         .option(\"header\", \"true\") \\\n",
    "#         .mode(\"overwrite\") \\\n",
    "#         .save(f\"s3a://{spark_bucket}/binance.bars\")\n",
    "\n",
    "# symbols_df.write \\\n",
    "#         .format(\"csv\") \\\n",
    "#         .option(\"header\", \"true\") \\\n",
    "#         .mode(\"overwrite\") \\\n",
    "#         .save(f\"s3a://{spark_bucket}/binance.symbols\")\n",
    "\n",
    "# latest_prices_df.write \\\n",
    "#         .format(\"csv\") \\\n",
    "#         .option(\"header\", \"true\") \\\n",
    "#         .mode(\"overwrite\") \\\n",
    "#         .save(f\"s3a://{spark_bucket}/binance.latest_prices\")\n",
    "\n",
    "# category_df.write \\\n",
    "#         .format(\"csv\") \\\n",
    "#         .option(\"header\", \"true\") \\\n",
    "#         .mode(\"overwrite\") \\\n",
    "#         .save(f\"s3a://{spark_bucket}/gecko.category\")\n",
    "\n",
    "# category_details_df.write \\\n",
    "#         .format(\"csv\") \\\n",
    "#         .option(\"header\", \"true\") \\\n",
    "#         .mode(\"overwrite\") \\\n",
    "#         .save(f\"s3a://{spark_bucket}/gecko.category_details\")\n",
    "\n",
    "# print(\"Spark run successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae42761-fc58-4c10-913e-d580400c4910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
